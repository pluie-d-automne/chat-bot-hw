{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZGWoSlLsi2YS"
      },
      "outputs": [],
      "source": [
        "# !pip install datasets\n",
        "# !pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RTiL2h4BX079"
      },
      "outputs": [],
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer\n",
        "from app.biencoder.sentence_bert import SentenceBert, encode\n",
        "from app.reranker.reranker import CrossEncoderBert, get_1st_rank"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uI8n_nO5hXhR",
        "outputId": "59c121e0-f8e5-4080-9efe-cc59d1919f22"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9lZyJVoe0Ri"
      },
      "source": [
        "# Crate dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "QOpe2Ld3s00t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3784b52f-4456-42c4-b85a-b9745fe41dda"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertModel(\n",
              "  (embeddings): Embeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (transformer): Transformer(\n",
              "    (layer): ModuleList(\n",
              "      (0-5): 6 x TransformerBlock(\n",
              "        (attention): MultiHeadSelfAttention(\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (ffn): FFN(\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (activation): GELUActivation()\n",
              "        )\n",
              "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "device = \"cpu\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "model = SentenceBert(device=device)\n",
        "model_location = \"/content/drive/MyDrive/weights/sentence_bert_biencoder\"\n",
        "model.bert_model = model.bert_model.from_pretrained(model_location)\n",
        "model.to(device)\n",
        "\n",
        "base = np.load(\"/content/drive/MyDrive/weights/faiss_base_tokens.npy\")\n",
        "homer_vocab = np.load(\"/content/drive/MyDrive/weights/faiss_base_originals.npy\")\n",
        "index = faiss.IndexFlatL2(base.shape[1])\n",
        "index.add(base)\n",
        "\n",
        "ce_model = CrossEncoderBert().to(device)\n",
        "ce_model.bert_model.from_pretrained(\"/content/drive/MyDrive/weights/ce_bert\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Hello, what's your name?\"\n",
        "pooled_embeds = encode(query, model.bert_tokenizer, model.bert_model, device)\n",
        "pooled_embeds = pooled_embeds.cpu().detach().numpy()\n",
        "D, I = index.search(pooled_embeds, 10)\n",
        "candidates = [homer_vocab[i] for i in I[0]]\n",
        "get_1st_rank(tokenizer, ce_model, query, candidates, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "67nAeNrR_CAw",
        "outputId": "76abfa7b-3003-4ca5-a4be-e8302b5572ab"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello? Hello? Hello taste... where are you?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Welcome to Springfield\"\n",
        "pooled_embeds = encode(query, model.bert_tokenizer, model.bert_model, device)\n",
        "pooled_embeds = pooled_embeds.cpu().detach().numpy()\n",
        "D, I = index.search(pooled_embeds, 10)\n",
        "candidates = [homer_vocab[i] for i in I[0]]\n",
        "get_1st_rank(tokenizer, ce_model, query, candidates, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Rb9GOo4A_Ouz",
        "outputId": "5306e1e0-a614-4809-bdfb-08447969ca13"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'New Springfield rocks!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"I am here\"\n",
        "pooled_embeds = encode(query, model.bert_tokenizer, model.bert_model, device)\n",
        "pooled_embeds = pooled_embeds.cpu().detach().numpy()\n",
        "D, I = index.search(pooled_embeds, 10)\n",
        "candidates = [homer_vocab[i] for i in I[0]]\n",
        "get_1st_rank(tokenizer, ce_model, query, candidates, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GeQ1bkN7_dCx",
        "outputId": "679afa44-165b-4750-d08b-067ae6160803"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Now it begins.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What did you do on a weekend?\"\n",
        "pooled_embeds = encode(query, model.bert_tokenizer, model.bert_model, device)\n",
        "pooled_embeds = pooled_embeds.cpu().detach().numpy()\n",
        "D, I = index.search(pooled_embeds, 10)\n",
        "candidates = [homer_vocab[i] for i in I[0]]\n",
        "get_1st_rank(tokenizer, ce_model, query, candidates, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "76Orny71_ikJ",
        "outputId": "799cb251-bdab-4f9d-a11d-16c37c3dc536"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Did you say life story?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"No, I didn't. Did you?\"\n",
        "pooled_embeds = encode(query, model.bert_tokenizer, model.bert_model, device)\n",
        "pooled_embeds = pooled_embeds.cpu().detach().numpy()\n",
        "D, I = index.search(pooled_embeds, 10)\n",
        "candidates = [homer_vocab[i] for i in I[0]]\n",
        "get_1st_rank(tokenizer, ce_model, query, candidates, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nqzAwlFz_tX9",
        "outputId": "9663e7d7-a063-40f7-e9cf-45b07fefafae"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"You... didn't?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Yes, I did't. Why are you so surprised?\"\n",
        "pooled_embeds = encode(query, model.bert_tokenizer, model.bert_model, device)\n",
        "pooled_embeds = pooled_embeds.cpu().detach().numpy()\n",
        "D, I = index.search(pooled_embeds, 10)\n",
        "candidates = [homer_vocab[i] for i in I[0]]\n",
        "get_1st_rank(tokenizer, ce_model, query, candidates, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mPRBG65g_ysL",
        "outputId": "bf248514-b1d0-436a-f83e-7ba95387d803"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Then, yes.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}